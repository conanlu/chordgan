{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "GANMIDItest.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXqiXvjmGkVv"
      },
      "source": [
        "# 1. Imports and Loading Data\r\n",
        "Before running, please upload the following to the \"Files\" tab:\r\n",
        "- reverse_pianoroll.py\r\n",
        "- convert.py\r\n",
        "- Pop_Music_Midi.zip\r\n",
        "\r\n",
        "All can be found on GitHub (github.com/conanlu/composeGAN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR2xjd5_8g2N"
      },
      "source": [
        "!pip install pretty_midi\r\n",
        "!pip install librosa\r\n",
        "import pretty_midi\r\n",
        "import reverse_pianoroll\r\n",
        "import convert\r\n",
        "import librosa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNiQvohD8g25"
      },
      "source": [
        "import numpy as np\r\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPDRHb10L7JO",
        "outputId": "698806cc-68e5-444d-df59-38abf6993a18"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWV1ONBqEj1t"
      },
      "source": [
        "#all necessary imports: use pip install [library name] to add to environment\n",
        "#this notebook was run in 2019 with tensorflow version 1.15. some functions may or may not work with tensorflow > 2.0\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import os\n",
        "from os import listdir\n",
        "import glob\n",
        "#import pretty_midi\n",
        "#import librosa\n",
        "\n",
        "#python script, in github repo\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0MVvlIeEj1v"
      },
      "source": [
        "#add songs to data\n",
        "def get_songs(path):\n",
        "    files = glob.glob('{}/*.mid*'.format(path))\n",
        "    songs = []\n",
        "    for f in files:\n",
        "        try:\n",
        "            data = pretty_midi.PrettyMIDI(f)\n",
        "            song = data.get_piano_roll(fs=16)\n",
        "            song = convert.forward(song)\n",
        "            #song = np.transpose(song) - if your code matrices aren't working, try uncommenting this. the convert.py file might not be updated\n",
        "            songs.append(song)\n",
        "        except Exception as e:\n",
        "            raise e           \n",
        "    return songs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MYRJza_Ej1v"
      },
      "source": [
        "#custom function to extract chroma features from song\n",
        "def get_chromas(songs):\n",
        "    chromas = []\n",
        "    for song in songs: \n",
        "        chroma = np.zeros(shape=(np.shape(song)[0], 12))\n",
        "        for i in np.arange(np.shape(song)[0]): \n",
        "            for j in np.arange(78):\n",
        "                if song[i][j] > 0:\n",
        "                    chroma[i][np.mod(j,12)] += 1\n",
        "        #print(np.shape(chroma))\n",
        "        chromas.append(chroma)\n",
        "                \n",
        "    return chromas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScsP7OZChZYd"
      },
      "source": [
        "!unzip Pop_Music_Midi.zip;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iihxLXwEj1w"
      },
      "source": [
        "songs = get_songs('Pop_Music_Midi')\n",
        "chromas = get_chromas(songs)\n",
        "print (\"{} songs processed\".format(len(songs)))\n",
        "print (\"{} songs processed\".format(len(chromas)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIhhTSj6GtvT"
      },
      "source": [
        "# 2. Setting Up GAN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIaKKrWmEj1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bd4c581-204f-4706-a2a6-c9edfde2e467"
      },
      "source": [
        "lowest_note = 0 #the index of the lowest note on the piano roll\n",
        "highest_note = 78 #the index of the highest note on the piano roll\n",
        "note_range = highest_note-lowest_note #the note range\n",
        "\n",
        "num_timesteps  = 4 #This is the number of timesteps that we will create at a time\n",
        "X_dim = 2*note_range*num_timesteps #This is the size of the visible layer. \n",
        "Z_dim = 12*num_timesteps\n",
        "n_hidden = 50 #This is the size of the hidden layer\n",
        "\n",
        "print(X_dim,Z_dim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "624 48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDpINNjpEj1x"
      },
      "source": [
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24NXtz5IEj1x"
      },
      "source": [
        "#setting up model, discriminator weights and biases\n",
        "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
        "\n",
        "\n",
        "D_W1 = tf.Variable(xavier_init([X_dim+Z_dim, 512]))\n",
        "D_b1 = tf.Variable(tf.zeros(shape=[512]))\n",
        "\n",
        "D_W2 = tf.Variable(xavier_init([512, 1]))\n",
        "D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
        "\n",
        "theta_D = [D_W1, D_W2, D_b1, D_b2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRLHyW-CEj1x"
      },
      "source": [
        "#setting up model, generator weights and biases\n",
        "\n",
        "#z is the space we're generating from\n",
        "Z = tf.placeholder(tf.float32, shape=[None, Z_dim])\n",
        "\n",
        "G_W1 = tf.Variable(xavier_init([Z_dim, 128]))\n",
        "G_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
        "\n",
        "G_W2 = tf.Variable(xavier_init([128, X_dim]))\n",
        "G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
        "\n",
        "theta_G = [G_W1, G_W2, G_b1, G_b2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIjKz4MwEj1x"
      },
      "source": [
        "def generator(z):\n",
        "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
        "    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2\n",
        "    G_prob = tf.nn.sigmoid(G_log_prob)\n",
        "\n",
        "    return G_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWImNLv-Ej1y"
      },
      "source": [
        "def discriminator(x,c):\n",
        "    D_h1 = tf.nn.relu(tf.matmul(tf.concat([x,c],1), D_W1) + D_b1)\n",
        "    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
        "    D_prob = tf.nn.sigmoid(D_logit)\n",
        "\n",
        "    return D_prob, D_logit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI8yFjDWEj1y"
      },
      "source": [
        "def plot(samples):\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    gs = gridspec.GridSpec(4, 4)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, sample in enumerate(samples):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "\n",
        "        plt.imshow(sample.reshape(78, 30), cmap='Greys_r')\n",
        "\n",
        "\n",
        "    return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKNB6f2oEj1y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e450e40f-7652-44d3-888e-d38f0faab224"
      },
      "source": [
        "print (np.shape(Z))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8CrxuCaEj1z"
      },
      "source": [
        "G_sample = generator(Z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eHEwK5BEj10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c718d5-2c4c-4ebc-df17-43a56bd6cf73"
      },
      "source": [
        "print(note_range)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjJ7f5I-Ej10"
      },
      "source": [
        "D_real, D_logit_real = discriminator(X,Z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8992jJOEj10"
      },
      "source": [
        "D_fake, D_logit_fake = discriminator(G_sample,Z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcYoVloPEj10"
      },
      "source": [
        "\n",
        "# Alternative losses:\n",
        "# -------------------\n",
        "D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
        "D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
        "D_loss = D_loss_real + D_loss_fake\n",
        "G_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))\n",
        "G_loss_L1 = tf.reduce_mean(tf.losses.mean_squared_error(X,G_sample))\n",
        "G_loss = G_loss_fake + 100*G_loss_L1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc9zTKiEEj11"
      },
      "source": [
        "#optimizing functions\n",
        "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n",
        "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_yjcm__Ej11"
      },
      "source": [
        "#output midi file folder\n",
        "if not os.path.exists('out/'):\n",
        "    os.makedirs('out/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMfONb8gEj11"
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5f8GfILEj11"
      },
      "source": [
        "# old comment:\n",
        "#         for song in songs:\n",
        "#         # The songs are stored in a time x notes format. The size of each song is timesteps_in_song x 2*note_range\n",
        "#         # Here we reshape the songs so that each training example is a vector with num_timesteps x 2*note_range elements\n",
        "#         song = np.array(song)\n",
        "#         song = song[:np.floor(song.shape[0]/num_timesteps).astype(int)*num_timesteps]\n",
        "#         song = np.reshape(song, [int(song.shape[0]/num_timesteps), song.shape[1]*num_timesteps])\n",
        "#         # Train the RBM on batch_size examples at a time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI2HBr6YGzkM"
      },
      "source": [
        "# 3. Training GAN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "FZBAHllDEj11"
      },
      "source": [
        "i = 0\n",
        "num_epochs = 200000\n",
        "batch_size = 10\n",
        "#commented out print statements output different losses, and plotting functions plot the piano roll and chroma.\n",
        "while i <= num_epochs:\n",
        "    for song, chroma in zip(songs, chromas):      \n",
        "        # The songs are stored in a time x notes format. The size of each song is timesteps_in_song x 2*note_range\n",
        "        # Here we reshape the songs so that each training example is a vector with num_timesteps x 2*note_range elements    \n",
        "        song = np.array(song)     \n",
        "        #print(np.shape(song))  \n",
        "        song_steps = np.floor(song.shape[0]/num_timesteps).astype(int)\n",
        "        song = song[:song_steps*num_timesteps]\n",
        "        song = np.reshape(song, [song_steps, song.shape[1]*num_timesteps])  \n",
        "        chroma = np.array(chroma)\n",
        "        #print(np.shape(chroma)\n",
        "        chroma = chroma[:song_steps*num_timesteps]\n",
        "        chroma = np.reshape(chroma, [song_steps, chroma.shape[1]*num_timesteps])                \n",
        "        batch_size = min(batch_size,len(song))\n",
        "        # Train the RBM on batch_size examples at a time\n",
        "        for ind in range(0, len(song), batch_size):       \n",
        "            X_mb = song[ind:ind+batch_size]\n",
        "            ch = chroma[ind:ind+batch_size]\n",
        "#            _, loss = sess.run([solver, vae_loss], feed_dict={X: X_mb})\n",
        "            _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: ch})\n",
        "            _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={X: X_mb, Z: ch})\n",
        "    \n",
        "            if i % 1000 == 0:\n",
        "                # print('Iter: {}'.format(i))\n",
        "                dloss = ('D_Loss: {:.4}'. format(D_loss_curr))\n",
        "                gloss = ('G_Loss: {:.4}'. format(G_loss_curr))\n",
        "                #print(dloss)\n",
        "                #print(gloss)\n",
        "                \n",
        "#             samples = sess.run(X_samples, feed_dict={z: np.random.randn(1,z_dim)})\n",
        "\n",
        "                samples = sess.run(G_sample, feed_dict={Z: ch}) #or here? lol i think it's here actually\n",
        "#                 print(np.shape(samples), np.shape(ch))\n",
        "        \n",
        "                S = np.reshape(samples, (ch.shape[0]*num_timesteps, 2*note_range))\n",
        "                thresh_S = S>=0.5\n",
        "\n",
        "                thresh_S = np.transpose(thresh_S)\n",
        "\n",
        "\n",
        "                C = np.reshape(ch, (ch.shape[0]*num_timesteps, 12))\n",
        "\n",
        "                test = reverse_pianoroll.piano_roll_to_pretty_midi(convert.back(thresh_S), fs=16)\n",
        "                test.write('out/{}.mid'.format(i))\n",
        "\n",
        "            i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9svDngpHzty"
      },
      "source": [
        "#4. Style Transfer with New Genre Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSzNXQleEj13"
      },
      "source": [
        "#for testing, i'll be using a different dataset of MIDI files to input into the generator here.\n",
        "test_song = get_songs(\"Classical_Music_Midi\")\n",
        "test_chromaz = get_chromas(test_song)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-lb4wigiXTm"
      },
      "source": [
        "#converted midi file folder\r\n",
        "if not os.path.exists('converted/'):\r\n",
        "    os.makedirs('converted/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1yURaYKEj14"
      },
      "source": [
        "\n",
        "\n",
        "i = 0\n",
        "\n",
        "for c in test_chromaz:\n",
        "    test_chroma = np.array(c)\n",
        "    \n",
        "\n",
        "    test_chroma = test_chroma[:np.floor(test_chroma.shape[0]/num_timesteps).astype(int)*num_timesteps]\n",
        "    test_chroma = np.reshape(test_chroma, [int(test_chroma.shape[0]/num_timesteps), test_chroma.shape[1]*num_timesteps])\n",
        "    #chroma = np.reshape(chroma, [song_steps, chroma.shape[1]*num_timesteps])\n",
        "       \n",
        "    out_samples = sess.run(G_sample, feed_dict={Z: test_chroma})\n",
        "    #print(np.shape(test_chroma),np.shape(samples))\n",
        "    \n",
        "    #print(np.floor(samples.shape[0]*samples.shape[1]/2/note_range).astype(int))\n",
        "    \n",
        "    S = np.reshape(out_samples, (np.floor(out_samples.shape[0]*out_samples.shape[1]/2/note_range).astype(int), 2*note_range))\n",
        "    C = np.reshape(test_chroma, (test_chroma.shape[0]*num_timesteps, 12))\n",
        "    #print(np.shape(S), np.shape(C))\n",
        "    thresh_S = S>=0.5\n",
        "\n",
        "    \n",
        "    # plt.figure(figsize=(30,18))\n",
        "    # plt.subplot(1,2,1)\n",
        "    # plt.imshow(S)\n",
        "    # plt.subplot(1,2,2)\n",
        "    # plt.imshow(C)\n",
        "    # #plt.tight_layout()\n",
        "    # plt.pause(0.1)\n",
        "\n",
        "\n",
        "    test = reverse_pianoroll.piano_roll_to_pretty_midi(convert.back(thresh_S), fs=16)\n",
        "    test.write('converted/{}.mid'.format(i))\n",
        "\n",
        "    # midi_manipulation.noteStateMatrixToMidi(thresh_S, \"new/generated_chord_{}\".format(i))\n",
        "    # i+=1\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}